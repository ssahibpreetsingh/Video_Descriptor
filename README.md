# Video-Summarization
The goal of the project was to detect activities, objects and background from videos and generate a simple summary based on model outputs. Team made use of Transfer Learning with R2plus1D model (trained on Kinetics400 dataset) for activity recognition from videos and fine tuned it for custom  dataset created by our team. Used pre-trained VGG16 model (trained on classes365 dataset) for background detection from image and YOLOv5 for object detection. Finally the output from all these models was processed and given to another open source pre-trained model Key2Text that helped create meaningful sentences from hint words. A Flask app was created to deploy the model on web. Also a Docker image has been built and registered on DockerHub so that project is accessible from anywhere.
