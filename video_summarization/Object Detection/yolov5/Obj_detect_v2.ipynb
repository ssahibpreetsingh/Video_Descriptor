{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "from torch import nn\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.transforms as tt\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "from torchvision.models.video import r2plus1d_18, R2Plus1D_18_Weights\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\hub.py:294: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
      "  warnings.warn(\n",
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to C:\\Users\\hp/.cache\\torch\\hub\\master.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['gitpython>=3.1.30', 'setuptools>=65.5.1'] not found, attempting AutoUpdate...\n",
      "Collecting gitpython>=3.1.30\n",
      "  Downloading GitPython-3.1.40-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting setuptools>=65.5.1\n",
      "  Downloading setuptools-69.0.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30)\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
      "   -------------------------------------- 190.6/190.6 kB 888.3 kB/s eta 0:00:00\n",
      "Downloading setuptools-69.0.3-py3-none-any.whl (819 kB)\n",
      "   -------------------------------------- 819.5/819.5 kB 700.1 kB/s eta 0:00:00\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 62.7/62.7 kB 1.7 MB/s eta 0:00:00\n",
      "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: smmap, setuptools, gitdb, gitpython\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 65.5.0\n",
      "    Uninstalling setuptools-65.5.0:\n",
      "      Successfully uninstalled setuptools-65.5.0\n",
      "Successfully installed gitdb-4.0.11 gitpython-3.1.40 setuptools-69.0.3 smmap-5.0.1\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 44.2s, installed 2 packages: ['gitpython>=3.1.30', 'setuptools>=65.5.1']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2024-1-7 Python-3.11.5 torch-2.1.1+cpu CPU\n",
      "\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
      "100%|██████████| 14.1M/14.1M [00:26<00:00, 564kB/s] \n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "  model=joblib.load(\"yolov5s.joblib\")\n",
    "except:\n",
    "  model=torch.hub.load(\"ultralytics/yolov5\",\"yolov5s\",pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yolov5s.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joblib.dump(model,\"yolov5s.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 --------------------------\n",
      "2 --------------------------\n",
      "3 --------------------------\n",
      "4 --------------------------\n",
      "5 --------------------------\n",
      "6 --------------------------\n",
      "7 --------------------------\n",
      "8 --------------------------\n",
      "9 --------------------------\n",
      "10 --------------------------\n",
      "11 --------------------------\n",
      "12 --------------------------\n",
      "13 --------------------------\n",
      "14 --------------------------\n",
      "15 --------------------------\n",
      "16 --------------------------\n",
      "17 --------------------------\n",
      "18 --------------------------\n",
      "19 --------------------------\n",
      "20 --------------------------\n",
      "21 --------------------------\n",
      "22 --------------------------\n",
      "23 --------------------------\n",
      "24 --------------------------\n",
      "25 --------------------------\n",
      "26 --------------------------\n",
      "27 --------------------------\n"
     ]
    }
   ],
   "source": [
    "video_path = r\"D:\\\\cdac\\\\Project\\\\walktest.mp4\"\n",
    "try:\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get Frame counts\n",
    "    frame_count=cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    # Get FPS\n",
    "    FPS=cap.get(cv2.CAP_PROP_FPS)\n",
    "    # skip window\n",
    "    skip_window=int(3*FPS//9)\n",
    "\n",
    "    # video len\n",
    "    vid_len=frame_count/FPS\n",
    "    thresh=int((vid_len//3)*3)\n",
    "    # print(frame_count,thresh)\n",
    "\n",
    "    # Define the codec and create a VideoWriter object to save the output\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "    output_file = r\"D:\\\\cdac\\\\Project\\\\Main Project\\\\Pratik obj detection\\\\yolov5\\\\output.avi\"\n",
    "    video_writer = cv2.VideoWriter(output_file, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "    # Open a text file for storing object names\n",
    "    text_file = open(r\"D:\\\\cdac\\\\Project\\\\Main Project\\\\Pratik obj detection\\\\yolov5\\\\detected_objects.txt\", \"w\")\n",
    "    \n",
    "    fcount=0\n",
    "    while fcount<(thresh*3):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, fcount * skip_window)\n",
    "        fcount+=1\n",
    "        print(fcount,\"--------------------------\")\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        height, width, channels = frame.shape\n",
    "\n",
    "        results = model(frame)  # inference\n",
    "        outs=results.pandas().xyxy[0][[\"name\",\"confidence\",\"xmin\",\"ymin\",\"xmax\",\"ymax\"]].values.tolist()\n",
    "\n",
    "        # Post-process the results\n",
    "        class_ids = []\n",
    "        confidences = []\n",
    "        boxes = []\n",
    "        #print(outs)\n",
    "        for out in outs:\n",
    "            x,y,w,h=out[2],out[3],1,1\n",
    "            text_file.write(f\"Label: {out[0]}   confidence: {out[1]}     x,y,w,h : {x,y,w,h}\\n\")\n",
    "        if  fcount%thresh==0:\n",
    "            text_file.write(\"----------------------------\\n\") \n",
    "        # Write the frame to the output video\n",
    "        cv2.imwrite(rf\"D:\\\\cdac\\\\Project\\\\Main Project\\\\Pratik obj detection\\yolov5\\\\detect_im\\\\{fcount}.jpg\",frame)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "finally:\n",
    "    # Release video capture and writer, and close the text file\n",
    "    cap.release()\n",
    "    video_writer.release()\n",
    "    text_file.close()\n",
    "\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
